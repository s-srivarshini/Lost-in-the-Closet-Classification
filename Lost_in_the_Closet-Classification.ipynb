{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222b43ae-2ae0-4db4-ae59-a1a3b8b9affc",
   "metadata": {},
   "source": [
    "##  Classification - Lost in the Closet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89afdaaf-5d87-40a1-93ca-279f2ddaaaf9",
   "metadata": {},
   "source": [
    "### 1 Introduction\n",
    "\n",
    "Dataset - Fashion_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "86907140-74aa-49dc-a932-9f740bdcd61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.1.0+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b087e-7cc2-4e1b-864b-6ddd1d613d15",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46a39a-6997-43bd-81c2-8ca510145d04",
   "metadata": {},
   "source": [
    "### 3 Lost in the closet (Classification)\n",
    "**You are an artist who secluded yourself for years to come up with the perfect design for a new brand\n",
    "of clothes. However, your time off from civilisation was not so beneficial since you cannot distinguish\n",
    "a T-shirt from a dress or a sneaker from a sandal any more. In order to address that issue, you choose\n",
    "to train a Convolutional Neural Network (using PyTorch) that will help you identify each cloth to\n",
    "match the perfect design you created. In order to train it, you decide to rely on the dataset fashion\n",
    "MNIST (https://github.com/zalandoresearch/fashion-mnist).**\n",
    "**You can access the data using the following lines (we strongly advise you to copy this code from the\n",
    "fashion mnist.py file attached to this coursework)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57417929-9148-43cd-9350-b306c0c5da18",
   "metadata": {},
   "source": [
    "#### Installing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bfdd7ffb-7a1b-4059-83a8-e7cbf2817e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c818d-25ff-4740-b401-2b72159bbea6",
   "metadata": {},
   "source": [
    "**1. Given the problem, what is the most appropriate loss function to use? Provide the name of the loss, its formula and the formula interpretation in your report.**\n",
    "\n",
    "**2. First convolutional layer: Kernel size (5 × 5), Stride size (1 × 1) and 32 output channels. Activation function)**\n",
    "\n",
    "**3. Max pooling layer: Kernel size (2 × 2) and Stride size (2 × 2).**\n",
    "\n",
    "**4. Second convolutional layer: Kernel size (5×5), Stride size (1 × 1) and 64 output channels.**\n",
    "\n",
    "**5. Max pooling layer: Kernel size (2 × 2) and Stride size (2 × 2).**\n",
    "\n",
    "**6. First fully-connected layer with input size being the output size of max pooling layer in 5. (flattened, i.e. 1024) and output size 1024.**\n",
    "\n",
    "**7. Second fully-connected layer with input size being the output size of fully connected layer in 6. (i.e. 1024) and output size 256.**\n",
    "\n",
    "**8. Output layer with input size being the output size of fully-connected layer in 7. (i.e. 256) and output size 10.**\n",
    "\n",
    "**For training, initialise your weights using the Xavier Uniform initialisation, use ReLU as the\n",
    "activation function, a learning rate of 0.1 with the SGD optimiser. You will train your neural\n",
    "network for 30 epochs. In your report, provide the following: (a) final (train and test) accuracy\n",
    "obtained; (b) plot of the accuracy on the training and test sets per each epoch, comment on the\n",
    "speed of performance changes across epochs; (c) plot of the train loss per epoch (total sum of\n",
    "per batch losses for each epoch) and comment on the speed of decr**ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "89ec8e5d-a276-4de8-89b9-c5d0da8349ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(root=\".\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_set = torchvision.datasets.FashionMNIST(root=\".\", train=False, download=True, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "# Fix the seed to be able to get the same randomness across runs and hence reproducible outcomes\n",
    "torch.manual_seed(0)\n",
    "# If you are using CuDNN, otherwise you can just ignore\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b8eb18b0-9c3e-4e8a-80ca-9786504a81f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs folder already exists\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")#using T4 GPU to make it faster\n",
    "\n",
    "# Store results in \"outputs\" folder\n",
    "if not os.path.exists(\"outputs\"):\n",
    "    os.makedirs(\"outputs\")\n",
    "    print(\"Outputs folder created\")\n",
    "else:\n",
    "    print(\"Outputs folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "491d318a-3f8e-4495-99a7-10cdc87edbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fashion_MNIST_CNN(nn.Module):\n",
    "    def __init__(self, activation=\"relu\", dropout_rate=0.0):\n",
    "        super(Fashion_MNIST_CNN, self).__init__()\n",
    "\n",
    "        self.num_classes = 10\n",
    "        if activation == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == \"elu\":\n",
    "            self.activation = nn.ELU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "\n",
    "        #3.1 Input = 28 * 28 * 1\n",
    "        self.cnn_layer = nn.Sequential(\n",
    "            #3.2 First convolution layer:Kernel size(5 x 5), Stride size(1 x 1) and 32 output channels.\n",
    "            #Activation function => ReLU\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1),\n",
    "            self.activation,\n",
    "\n",
    "            #3.3 Max pooling layer: Kernel size(2 x 2) and Stride size(2 x 2).\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            #3.4 Second convolutional layer: Kernel size (5×5), Stride size (1 × 1) and 64 output channels.\n",
    "            #Activation function => ReLU\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1),\n",
    "            self.activation,\n",
    "\n",
    "            #3.5 Max pooling layer: Kernel size (2 × 2) and Stride size (2 × 2).\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fcc = nn.Sequential(\n",
    "            #3.6 First fully-connected layer with input size being the output size of max pooling layer in 5. (flattened, i.e. 1024) and output size 1024.\n",
    "            #input = flattened output of second convolutional layer = 64 * 4 * 4\n",
    "            #64 = output channels of second convolutional layer\n",
    "            #4 * 4 = output size of second convolutional layer\n",
    "            #output = 1024\n",
    "            #Activation function = ReLU\n",
    "            nn.Linear(64 * 4 * 4, 1024), #\n",
    "            self.activation,\n",
    "\n",
    "            #3.7 Second fully-connected layer with input size being the output size of fully connected layer in 6. (i.e. 1024) and output size 256.\n",
    "            #input = 1024\n",
    "            #output = 256\n",
    "            #activation function = ReLU\n",
    "            nn.Linear(1024, 256),\n",
    "            self.activation,\n",
    "\n",
    "            #Add dropout layer\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "\n",
    "            #3.8 Output layer with input size being the output size of fully-connected layer in 7 and output size 10.\n",
    "            #output layer\n",
    "            #input = 256\n",
    "            #output = self.num_classes\n",
    "            #Activation function => softmax\n",
    "            nn.Linear(256, self.num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # first convolutional layer\n",
    "        x = self.cnn_layer(x)\n",
    "\n",
    "        # flatten the output of second convolutional layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # fully connected layers\n",
    "        x = self.fcc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6dad0b07-b5f4-4d7d-8b11-400b039749ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader):\n",
    "    total, correct = 0,0\n",
    "    model.eval()\n",
    "    # TO DO\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fb3db859-5c5e-4bde-a702-f37c6ced1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(layer):\n",
    "    # xaiver uniform initialisation\n",
    "    if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ba97e09c-ced0-4d57-bb38-876edcc70ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, lr, epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_accuracy = evaluation(model, train_loader)\n",
    "        train_acc.append(train_accuracy)\n",
    "        train_losses.append(running_loss)\n",
    "\n",
    "        test_accuracy = evaluation(model, test_loader)\n",
    "        test_acc.append(test_accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Train Loss: {running_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "    return model, train_losses, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "aaa2b275-dad7-4605-b734-ec193dc2ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1\n",
    "def fashion_mnist_model_training(activation=\"relu\", lr=0.1, epochs=30, dropout_rate=0.0):\n",
    "    model = Fashion_MNIST_CNN(activation=activation, dropout_rate=dropout_rate).to(device)\n",
    "    model.apply(weights_init)\n",
    "    # start training\n",
    "    model, train_losses, train_acc, test_acc = train(model, train_loader, test_loader, lr=lr, epochs=epochs)\n",
    "    torch.save(model.state_dict(), \"outputs/model.pth\")\n",
    "\n",
    "    #3.2 (a) Final (train and test) accuracy obtained\n",
    "    final_train_accuracy = train_acc[-1]\n",
    "    final_valid_accuracy = test_acc[-1]\n",
    "    print(f\"Final loss: {train_losses[-1]}\")\n",
    "    print(f\"Final train accuracy: {final_train_accuracy}\")\n",
    "    print(f\"Final valid accuracy: {final_valid_accuracy}\")\n",
    "\n",
    "\n",
    "    #(b) Plot accuracy on the training and test sets per each epochtorch.nn.CrossEntropyLoss\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc, label=\"Train Accuracy\")\n",
    "    plt.plot(test_acc, label=\"Validation Accuracy\")\n",
    "    plt.title(\"Accuracy vs Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    acc_filename = f\"outputs/accuracy_{activation}{lr}{dropout_rate}.jpg\"\n",
    "    plt.savefig(acc_filename)\n",
    "    plt.close()  # Close the figure to prevent it from displaying in a notebook environment\n",
    "    \n",
    "    \n",
    "    #(c) Plot of the train loss per epoch\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.title(\"Loss vs Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    loss_plot_filename = f\"outputs/loss_{activation}{lr}{dropout_rate}.jpg\"\n",
    "    plt.savefig(loss_plot_filename)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240b0c8-b2f6-4d40-badf-ebfbf1b50e06",
   "metadata": {},
   "source": [
    "**3.3 Run three experiments each time changing all the current activation functions to one of the\n",
    "following: Tanh, Sigmoid and ELU. In your report, provide only the final classification accuracy\n",
    "values (train and test) per activation function and comment on the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1391f90e-bfb1-4c06-90eb-3be9a9187a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.3\n",
    "def experimenting_with_activations():\n",
    "    # Try different activations and see how they affect the training and test accuracy\n",
    "    activations = [\"relu\", \"elu\", \"tanh\", \"sigmoid\"]\n",
    "    #print(\"---------------------------------------------------\")\n",
    "    print(\"Experimenting with different activations\")\n",
    "    for activation in activations:\n",
    "        print(f\"Using Activation: {activation}\")\n",
    "        fashion_mnist_model_training(activation=activation)\n",
    "    #print(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1b2e8a-7350-4680-8989-f79322cbd348",
   "metadata": {},
   "source": [
    "**3.4 Keeping ReLU, use 5 different learning rates: 0.001, 0.1, 0.5, 1, 10. In your report, provide the\n",
    "final train loss, as well as the final accuracy values for both train and test for each learning rate\n",
    "and comment on the trade-offs between speed and stability of convergence. Comment on why\n",
    "you get the Nan loss if any.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a0371039-a3cf-46ea-b156-964621f1752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.4\n",
    "def experimenting_with_learning_rates():\n",
    "    # Try different learning rates and see how they affect the training and test accuracy\n",
    "    learning_rates = [0.001, 0.1, 0.5, 1, 10]\n",
    "    activation = \"relu\"\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"Experimenting with different learning rates\")\n",
    "    for lr in learning_rates:\n",
    "        print(f\"Using Learning rate: {lr} and Activation: {activation}\")\n",
    "        fashion_mnist_model_training(activation=activation, lr=lr)\n",
    "    print(\"-------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689d4a5-ed04-4955-a7d6-3dbbc36ee33a",
   "metadata": {},
   "source": [
    "**3.5 Add a dropout of 0.3 rate on the second fully connected layer (keeping ReLU and learning rate\n",
    "0.1). In your report, provide the final train and test accuracy values and explain how the dropout\n",
    "affects the performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f5be67cd-19f1-4bac-8c72-98e47d639956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.5\n",
    "def experimenting_dropout():\n",
    "    # Check how dropout affects the performance\n",
    "    dropout_rate = 0.3\n",
    "    lr = 0.1\n",
    "    activation = \"relu\"\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Experimenting with dropout\")\n",
    "    print(f\"Using dropout rate: {dropout_rate}\")\n",
    "    fashion_mnist_model_training(activation=activation, lr=lr, epochs=30, dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f4e49f6b-a25f-4b46-838c-b6133bbcb71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting with different activations\n",
      "Using Activation: relu\n",
      "Epoch [1/30] - Train Loss: 979.4951 - Train Acc: 87.01% - Test Acc: 85.76%\n",
      "Epoch [2/30] - Train Loss: 614.6555 - Train Acc: 89.08% - Test Acc: 87.53%\n",
      "Epoch [3/30] - Train Loss: 520.5550 - Train Acc: 89.98% - Test Acc: 88.19%\n",
      "Epoch [4/30] - Train Loss: 465.1674 - Train Acc: 91.62% - Test Acc: 89.37%\n",
      "Epoch [5/30] - Train Loss: 418.1237 - Train Acc: 92.61% - Test Acc: 89.68%\n",
      "Epoch [6/30] - Train Loss: 374.2790 - Train Acc: 93.77% - Test Acc: 90.35%\n",
      "Epoch [7/30] - Train Loss: 342.5053 - Train Acc: 94.40% - Test Acc: 90.50%\n",
      "Epoch [8/30] - Train Loss: 306.7180 - Train Acc: 94.41% - Test Acc: 90.68%\n",
      "Epoch [9/30] - Train Loss: 279.6757 - Train Acc: 95.62% - Test Acc: 90.67%\n",
      "Epoch [10/30] - Train Loss: 248.6360 - Train Acc: 95.96% - Test Acc: 91.06%\n",
      "Epoch [11/30] - Train Loss: 224.8042 - Train Acc: 96.72% - Test Acc: 91.32%\n",
      "Epoch [12/30] - Train Loss: 203.5414 - Train Acc: 96.88% - Test Acc: 90.89%\n",
      "Epoch [13/30] - Train Loss: 183.0604 - Train Acc: 96.85% - Test Acc: 90.79%\n",
      "Epoch [14/30] - Train Loss: 167.0879 - Train Acc: 97.53% - Test Acc: 91.12%\n",
      "Epoch [15/30] - Train Loss: 156.9444 - Train Acc: 96.82% - Test Acc: 90.42%\n",
      "Epoch [16/30] - Train Loss: 136.5026 - Train Acc: 97.80% - Test Acc: 90.93%\n",
      "Epoch [17/30] - Train Loss: 120.9621 - Train Acc: 97.76% - Test Acc: 90.99%\n",
      "Epoch [18/30] - Train Loss: 109.9334 - Train Acc: 97.63% - Test Acc: 90.38%\n",
      "Epoch [19/30] - Train Loss: 95.6861 - Train Acc: 98.54% - Test Acc: 90.99%\n",
      "Epoch [20/30] - Train Loss: 99.7750 - Train Acc: 98.55% - Test Acc: 91.15%\n",
      "Epoch [21/30] - Train Loss: 92.9031 - Train Acc: 98.81% - Test Acc: 91.12%\n",
      "Epoch [22/30] - Train Loss: 80.0863 - Train Acc: 98.68% - Test Acc: 91.05%\n",
      "Epoch [23/30] - Train Loss: 80.7584 - Train Acc: 98.30% - Test Acc: 90.88%\n",
      "Epoch [24/30] - Train Loss: 74.7820 - Train Acc: 99.19% - Test Acc: 91.40%\n",
      "Epoch [25/30] - Train Loss: 66.2072 - Train Acc: 98.79% - Test Acc: 90.72%\n",
      "Epoch [26/30] - Train Loss: 66.0181 - Train Acc: 99.22% - Test Acc: 90.87%\n",
      "Epoch [27/30] - Train Loss: 62.6477 - Train Acc: 99.04% - Test Acc: 91.16%\n",
      "Epoch [28/30] - Train Loss: 56.3934 - Train Acc: 99.10% - Test Acc: 90.77%\n",
      "Epoch [29/30] - Train Loss: 59.7729 - Train Acc: 98.23% - Test Acc: 90.20%\n",
      "Epoch [30/30] - Train Loss: 51.8405 - Train Acc: 99.30% - Test Acc: 90.95%\n",
      "Final loss: 51.840499805402715\n",
      "Final train accuracy: 99.29666666666667\n",
      "Final valid accuracy: 90.95\n",
      "Using Activation: elu\n",
      "Epoch [1/30] - Train Loss: 849.3840 - Train Acc: 88.16% - Test Acc: 87.06%\n",
      "Epoch [2/30] - Train Loss: 586.7562 - Train Acc: 89.00% - Test Acc: 87.46%\n",
      "Epoch [3/30] - Train Loss: 508.0171 - Train Acc: 91.53% - Test Acc: 89.00%\n",
      "Epoch [4/30] - Train Loss: 448.7481 - Train Acc: 91.36% - Test Acc: 88.77%\n",
      "Epoch [5/30] - Train Loss: 400.5143 - Train Acc: 92.31% - Test Acc: 89.00%\n",
      "Epoch [6/30] - Train Loss: 360.6800 - Train Acc: 93.32% - Test Acc: 89.62%\n",
      "Epoch [7/30] - Train Loss: 318.4849 - Train Acc: 94.66% - Test Acc: 90.52%\n",
      "Epoch [8/30] - Train Loss: 287.9172 - Train Acc: 95.04% - Test Acc: 90.04%\n",
      "Epoch [9/30] - Train Loss: 256.9302 - Train Acc: 94.98% - Test Acc: 89.94%\n",
      "Epoch [10/30] - Train Loss: 228.6107 - Train Acc: 96.62% - Test Acc: 90.87%\n",
      "Epoch [11/30] - Train Loss: 210.9260 - Train Acc: 96.37% - Test Acc: 90.19%\n",
      "Epoch [12/30] - Train Loss: 187.1799 - Train Acc: 96.41% - Test Acc: 90.59%\n",
      "Epoch [13/30] - Train Loss: 169.9930 - Train Acc: 97.20% - Test Acc: 90.58%\n",
      "Epoch [14/30] - Train Loss: 154.2704 - Train Acc: 97.84% - Test Acc: 90.87%\n",
      "Epoch [15/30] - Train Loss: 144.4503 - Train Acc: 97.61% - Test Acc: 90.38%\n",
      "Epoch [16/30] - Train Loss: 134.6004 - Train Acc: 97.84% - Test Acc: 90.45%\n",
      "Epoch [17/30] - Train Loss: 119.0696 - Train Acc: 98.19% - Test Acc: 90.46%\n",
      "Epoch [18/30] - Train Loss: 113.0583 - Train Acc: 98.10% - Test Acc: 90.71%\n",
      "Epoch [19/30] - Train Loss: 124.3739 - Train Acc: 98.30% - Test Acc: 90.56%\n",
      "Epoch [20/30] - Train Loss: 100.9172 - Train Acc: 98.12% - Test Acc: 89.92%\n",
      "Epoch [21/30] - Train Loss: 92.8270 - Train Acc: 98.13% - Test Acc: 90.66%\n",
      "Epoch [22/30] - Train Loss: 99.4894 - Train Acc: 98.83% - Test Acc: 90.32%\n",
      "Epoch [23/30] - Train Loss: 80.5672 - Train Acc: 98.71% - Test Acc: 90.54%\n",
      "Epoch [24/30] - Train Loss: 63.8387 - Train Acc: 99.03% - Test Acc: 90.73%\n",
      "Epoch [25/30] - Train Loss: 90.8736 - Train Acc: 98.21% - Test Acc: 90.32%\n",
      "Epoch [26/30] - Train Loss: 100.9673 - Train Acc: 97.79% - Test Acc: 89.81%\n",
      "Epoch [27/30] - Train Loss: 79.8171 - Train Acc: 98.62% - Test Acc: 90.06%\n",
      "Epoch [28/30] - Train Loss: 71.1823 - Train Acc: 99.17% - Test Acc: 90.96%\n",
      "Epoch [29/30] - Train Loss: 66.1141 - Train Acc: 98.85% - Test Acc: 90.50%\n",
      "Epoch [30/30] - Train Loss: 74.0001 - Train Acc: 99.00% - Test Acc: 90.19%\n",
      "Final loss: 74.00012654527131\n",
      "Final train accuracy: 99.005\n",
      "Final valid accuracy: 90.19\n",
      "Using Activation: tanh\n",
      "Epoch [1/30] - Train Loss: 851.7471 - Train Acc: 88.67% - Test Acc: 87.86%\n",
      "Epoch [2/30] - Train Loss: 589.2922 - Train Acc: 90.78% - Test Acc: 88.90%\n",
      "Epoch [3/30] - Train Loss: 494.6370 - Train Acc: 91.83% - Test Acc: 89.29%\n",
      "Epoch [4/30] - Train Loss: 433.4518 - Train Acc: 93.02% - Test Acc: 90.06%\n",
      "Epoch [5/30] - Train Loss: 378.9569 - Train Acc: 93.97% - Test Acc: 90.21%\n",
      "Epoch [6/30] - Train Loss: 332.4477 - Train Acc: 94.11% - Test Acc: 89.93%\n",
      "Epoch [7/30] - Train Loss: 287.8140 - Train Acc: 95.71% - Test Acc: 90.87%\n",
      "Epoch [8/30] - Train Loss: 246.9615 - Train Acc: 96.44% - Test Acc: 90.75%\n",
      "Epoch [9/30] - Train Loss: 212.3651 - Train Acc: 96.81% - Test Acc: 90.55%\n",
      "Epoch [10/30] - Train Loss: 176.1103 - Train Acc: 96.75% - Test Acc: 90.13%\n",
      "Epoch [11/30] - Train Loss: 146.1482 - Train Acc: 97.03% - Test Acc: 90.28%\n",
      "Epoch [12/30] - Train Loss: 120.8598 - Train Acc: 98.07% - Test Acc: 90.64%\n",
      "Epoch [13/30] - Train Loss: 100.7986 - Train Acc: 98.34% - Test Acc: 90.57%\n",
      "Epoch [14/30] - Train Loss: 76.5320 - Train Acc: 99.16% - Test Acc: 91.23%\n",
      "Epoch [15/30] - Train Loss: 61.6472 - Train Acc: 98.70% - Test Acc: 91.02%\n",
      "Epoch [16/30] - Train Loss: 45.5963 - Train Acc: 99.70% - Test Acc: 91.27%\n",
      "Epoch [17/30] - Train Loss: 22.9940 - Train Acc: 99.72% - Test Acc: 91.36%\n",
      "Epoch [18/30] - Train Loss: 12.1647 - Train Acc: 99.89% - Test Acc: 91.18%\n",
      "Epoch [19/30] - Train Loss: 5.4875 - Train Acc: 100.00% - Test Acc: 91.43%\n",
      "Epoch [20/30] - Train Loss: 2.9499 - Train Acc: 100.00% - Test Acc: 91.52%\n",
      "Epoch [21/30] - Train Loss: 2.2412 - Train Acc: 100.00% - Test Acc: 91.52%\n",
      "Epoch [22/30] - Train Loss: 1.8284 - Train Acc: 100.00% - Test Acc: 91.56%\n",
      "Epoch [23/30] - Train Loss: 1.6071 - Train Acc: 100.00% - Test Acc: 91.50%\n",
      "Epoch [24/30] - Train Loss: 1.4184 - Train Acc: 100.00% - Test Acc: 91.52%\n",
      "Epoch [25/30] - Train Loss: 1.2833 - Train Acc: 100.00% - Test Acc: 91.54%\n",
      "Epoch [26/30] - Train Loss: 1.1708 - Train Acc: 100.00% - Test Acc: 91.57%\n",
      "Epoch [27/30] - Train Loss: 1.0722 - Train Acc: 100.00% - Test Acc: 91.48%\n",
      "Epoch [28/30] - Train Loss: 0.9933 - Train Acc: 100.00% - Test Acc: 91.48%\n",
      "Epoch [29/30] - Train Loss: 0.9233 - Train Acc: 100.00% - Test Acc: 91.53%\n",
      "Epoch [30/30] - Train Loss: 0.8614 - Train Acc: 100.00% - Test Acc: 91.45%\n",
      "Final loss: 0.861394335022851\n",
      "Final train accuracy: 100.0\n",
      "Final valid accuracy: 91.45\n",
      "Using Activation: sigmoid\n",
      "Epoch [1/30] - Train Loss: 4340.1478 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [2/30] - Train Loss: 4319.1719 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [3/30] - Train Loss: 4027.1654 - Train Acc: 50.90% - Test Acc: 50.70%\n",
      "Epoch [4/30] - Train Loss: 1676.8764 - Train Acc: 69.93% - Test Acc: 69.26%\n",
      "Epoch [5/30] - Train Loss: 1306.3636 - Train Acc: 72.84% - Test Acc: 72.13%\n",
      "Epoch [6/30] - Train Loss: 1182.1521 - Train Acc: 77.26% - Test Acc: 76.80%\n",
      "Epoch [7/30] - Train Loss: 1085.6643 - Train Acc: 77.00% - Test Acc: 75.67%\n",
      "Epoch [8/30] - Train Loss: 1002.7948 - Train Acc: 80.85% - Test Acc: 79.76%\n",
      "Epoch [9/30] - Train Loss: 932.7624 - Train Acc: 81.52% - Test Acc: 79.99%\n",
      "Epoch [10/30] - Train Loss: 879.5300 - Train Acc: 83.48% - Test Acc: 82.05%\n",
      "Epoch [11/30] - Train Loss: 835.9916 - Train Acc: 84.36% - Test Acc: 83.21%\n",
      "Epoch [12/30] - Train Loss: 799.3098 - Train Acc: 84.30% - Test Acc: 83.36%\n",
      "Epoch [13/30] - Train Loss: 761.3068 - Train Acc: 85.07% - Test Acc: 84.31%\n",
      "Epoch [14/30] - Train Loss: 733.4295 - Train Acc: 85.30% - Test Acc: 83.87%\n",
      "Epoch [15/30] - Train Loss: 704.3632 - Train Acc: 86.96% - Test Acc: 85.84%\n",
      "Epoch [16/30] - Train Loss: 680.3301 - Train Acc: 87.11% - Test Acc: 85.74%\n",
      "Epoch [17/30] - Train Loss: 661.7038 - Train Acc: 87.39% - Test Acc: 86.24%\n",
      "Epoch [18/30] - Train Loss: 646.0060 - Train Acc: 87.13% - Test Acc: 86.21%\n",
      "Epoch [19/30] - Train Loss: 625.3739 - Train Acc: 88.08% - Test Acc: 86.76%\n",
      "Epoch [20/30] - Train Loss: 610.4574 - Train Acc: 88.17% - Test Acc: 87.09%\n",
      "Epoch [21/30] - Train Loss: 599.9193 - Train Acc: 88.54% - Test Acc: 87.25%\n",
      "Epoch [22/30] - Train Loss: 584.9136 - Train Acc: 88.82% - Test Acc: 87.55%\n",
      "Epoch [23/30] - Train Loss: 573.2865 - Train Acc: 88.89% - Test Acc: 87.56%\n",
      "Epoch [24/30] - Train Loss: 563.8974 - Train Acc: 88.97% - Test Acc: 87.61%\n",
      "Epoch [25/30] - Train Loss: 554.4266 - Train Acc: 89.96% - Test Acc: 88.67%\n",
      "Epoch [26/30] - Train Loss: 543.5133 - Train Acc: 88.83% - Test Acc: 87.41%\n",
      "Epoch [27/30] - Train Loss: 534.4449 - Train Acc: 88.67% - Test Acc: 87.31%\n",
      "Epoch [28/30] - Train Loss: 527.7641 - Train Acc: 89.36% - Test Acc: 88.02%\n",
      "Epoch [29/30] - Train Loss: 516.5496 - Train Acc: 89.53% - Test Acc: 88.08%\n",
      "Epoch [30/30] - Train Loss: 508.4431 - Train Acc: 89.67% - Test Acc: 87.89%\n",
      "Final loss: 508.443068575114\n",
      "Final train accuracy: 89.67\n",
      "Final valid accuracy: 87.89\n"
     ]
    }
   ],
   "source": [
    "# Question 3.3\n",
    "experimenting_with_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bcf8f5f5-c9da-4a3b-98b3-10b20ee661b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Experimenting with different learning rates\n",
      "Using Learning rate: 0.001 and Activation: relu\n",
      "Epoch [1/30] - Train Loss: 3143.8315 - Train Acc: 66.77% - Test Acc: 66.64%\n",
      "Epoch [2/30] - Train Loss: 1550.0608 - Train Acc: 69.69% - Test Acc: 68.83%\n",
      "Epoch [3/30] - Train Loss: 1362.8149 - Train Acc: 74.72% - Test Acc: 73.99%\n",
      "Epoch [4/30] - Train Loss: 1253.4206 - Train Acc: 75.74% - Test Acc: 75.27%\n",
      "Epoch [5/30] - Train Loss: 1173.3805 - Train Acc: 77.32% - Test Acc: 76.54%\n",
      "Epoch [6/30] - Train Loss: 1115.1412 - Train Acc: 79.83% - Test Acc: 78.49%\n",
      "Epoch [7/30] - Train Loss: 1064.5458 - Train Acc: 78.56% - Test Acc: 77.87%\n",
      "Epoch [8/30] - Train Loss: 1023.2054 - Train Acc: 79.89% - Test Acc: 78.60%\n",
      "Epoch [9/30] - Train Loss: 984.2584 - Train Acc: 82.12% - Test Acc: 81.10%\n",
      "Epoch [10/30] - Train Loss: 952.5296 - Train Acc: 80.89% - Test Acc: 79.63%\n",
      "Epoch [11/30] - Train Loss: 925.4501 - Train Acc: 82.97% - Test Acc: 82.12%\n",
      "Epoch [12/30] - Train Loss: 896.3296 - Train Acc: 83.23% - Test Acc: 82.44%\n",
      "Epoch [13/30] - Train Loss: 874.1890 - Train Acc: 84.20% - Test Acc: 83.22%\n",
      "Epoch [14/30] - Train Loss: 855.0990 - Train Acc: 83.94% - Test Acc: 83.19%\n",
      "Epoch [15/30] - Train Loss: 835.6057 - Train Acc: 84.55% - Test Acc: 83.44%\n",
      "Epoch [16/30] - Train Loss: 820.5074 - Train Acc: 83.73% - Test Acc: 82.63%\n",
      "Epoch [17/30] - Train Loss: 804.9486 - Train Acc: 84.71% - Test Acc: 83.78%\n",
      "Epoch [18/30] - Train Loss: 790.6869 - Train Acc: 85.67% - Test Acc: 84.54%\n",
      "Epoch [19/30] - Train Loss: 777.1958 - Train Acc: 85.19% - Test Acc: 84.11%\n",
      "Epoch [20/30] - Train Loss: 763.5672 - Train Acc: 86.03% - Test Acc: 84.76%\n",
      "Epoch [21/30] - Train Loss: 752.8221 - Train Acc: 86.34% - Test Acc: 85.28%\n",
      "Epoch [22/30] - Train Loss: 739.2178 - Train Acc: 85.94% - Test Acc: 84.92%\n",
      "Epoch [23/30] - Train Loss: 728.6157 - Train Acc: 86.18% - Test Acc: 85.05%\n",
      "Epoch [24/30] - Train Loss: 718.6332 - Train Acc: 85.39% - Test Acc: 84.40%\n",
      "Epoch [25/30] - Train Loss: 708.3605 - Train Acc: 86.53% - Test Acc: 85.24%\n",
      "Epoch [26/30] - Train Loss: 700.4041 - Train Acc: 86.75% - Test Acc: 85.33%\n",
      "Epoch [27/30] - Train Loss: 691.3815 - Train Acc: 87.18% - Test Acc: 85.79%\n",
      "Epoch [28/30] - Train Loss: 681.7648 - Train Acc: 86.72% - Test Acc: 85.56%\n",
      "Epoch [29/30] - Train Loss: 673.4759 - Train Acc: 87.37% - Test Acc: 86.13%\n",
      "Epoch [30/30] - Train Loss: 667.7628 - Train Acc: 87.27% - Test Acc: 85.97%\n",
      "Final loss: 667.7628386095166\n",
      "Final train accuracy: 87.27166666666666\n",
      "Final valid accuracy: 85.97\n",
      "Using Learning rate: 0.1 and Activation: relu\n",
      "Epoch [1/30] - Train Loss: 999.0574 - Train Acc: 86.09% - Test Acc: 85.14%\n",
      "Epoch [2/30] - Train Loss: 619.8922 - Train Acc: 89.96% - Test Acc: 88.41%\n",
      "Epoch [3/30] - Train Loss: 529.3616 - Train Acc: 89.58% - Test Acc: 87.74%\n",
      "Epoch [4/30] - Train Loss: 468.6664 - Train Acc: 91.86% - Test Acc: 89.57%\n",
      "Epoch [5/30] - Train Loss: 423.0522 - Train Acc: 92.57% - Test Acc: 89.69%\n",
      "Epoch [6/30] - Train Loss: 381.6965 - Train Acc: 94.08% - Test Acc: 90.93%\n",
      "Epoch [7/30] - Train Loss: 344.3486 - Train Acc: 94.27% - Test Acc: 90.57%\n",
      "Epoch [8/30] - Train Loss: 311.1358 - Train Acc: 94.65% - Test Acc: 90.46%\n",
      "Epoch [9/30] - Train Loss: 279.2420 - Train Acc: 94.68% - Test Acc: 90.34%\n",
      "Epoch [10/30] - Train Loss: 252.7440 - Train Acc: 96.03% - Test Acc: 90.68%\n",
      "Epoch [11/30] - Train Loss: 229.1890 - Train Acc: 96.78% - Test Acc: 91.20%\n",
      "Epoch [12/30] - Train Loss: 206.1391 - Train Acc: 96.64% - Test Acc: 90.92%\n",
      "Epoch [13/30] - Train Loss: 183.6553 - Train Acc: 97.48% - Test Acc: 91.08%\n",
      "Epoch [14/30] - Train Loss: 171.1098 - Train Acc: 96.51% - Test Acc: 90.49%\n",
      "Epoch [15/30] - Train Loss: 148.4412 - Train Acc: 97.69% - Test Acc: 90.99%\n",
      "Epoch [16/30] - Train Loss: 138.7919 - Train Acc: 97.17% - Test Acc: 90.54%\n",
      "Epoch [17/30] - Train Loss: 134.0697 - Train Acc: 96.51% - Test Acc: 89.63%\n",
      "Epoch [18/30] - Train Loss: 121.9289 - Train Acc: 98.22% - Test Acc: 90.80%\n",
      "Epoch [19/30] - Train Loss: 109.2525 - Train Acc: 98.53% - Test Acc: 90.94%\n",
      "Epoch [20/30] - Train Loss: 99.0938 - Train Acc: 97.73% - Test Acc: 90.39%\n",
      "Epoch [21/30] - Train Loss: 103.2567 - Train Acc: 97.85% - Test Acc: 90.38%\n",
      "Epoch [22/30] - Train Loss: 93.9929 - Train Acc: 97.71% - Test Acc: 89.95%\n",
      "Epoch [23/30] - Train Loss: 77.3428 - Train Acc: 98.88% - Test Acc: 90.89%\n",
      "Epoch [24/30] - Train Loss: 69.7927 - Train Acc: 98.70% - Test Acc: 90.47%\n",
      "Epoch [25/30] - Train Loss: 68.6580 - Train Acc: 98.92% - Test Acc: 90.76%\n",
      "Epoch [26/30] - Train Loss: 61.2581 - Train Acc: 98.51% - Test Acc: 90.72%\n",
      "Epoch [27/30] - Train Loss: 67.2032 - Train Acc: 98.30% - Test Acc: 89.78%\n",
      "Epoch [28/30] - Train Loss: 57.2882 - Train Acc: 99.45% - Test Acc: 90.86%\n",
      "Epoch [29/30] - Train Loss: 48.5931 - Train Acc: 99.50% - Test Acc: 90.85%\n",
      "Epoch [30/30] - Train Loss: 49.9837 - Train Acc: 98.95% - Test Acc: 90.60%\n",
      "Final loss: 49.98367555229288\n",
      "Final train accuracy: 98.95166666666667\n",
      "Final valid accuracy: 90.6\n",
      "Using Learning rate: 0.5 and Activation: relu\n",
      "Epoch [1/30] - Train Loss: 1024.6496 - Train Acc: 85.90% - Test Acc: 84.65%\n",
      "Epoch [2/30] - Train Loss: 670.0654 - Train Acc: 88.86% - Test Acc: 86.81%\n",
      "Epoch [3/30] - Train Loss: 592.8589 - Train Acc: 89.44% - Test Acc: 87.42%\n",
      "Epoch [4/30] - Train Loss: 544.0468 - Train Acc: 90.00% - Test Acc: 87.51%\n",
      "Epoch [5/30] - Train Loss: 520.5155 - Train Acc: 90.63% - Test Acc: 87.61%\n",
      "Epoch [6/30] - Train Loss: 479.9234 - Train Acc: 90.53% - Test Acc: 87.30%\n",
      "Epoch [7/30] - Train Loss: 469.1874 - Train Acc: 90.49% - Test Acc: 87.12%\n",
      "Epoch [8/30] - Train Loss: 445.8859 - Train Acc: 90.23% - Test Acc: 86.96%\n",
      "Epoch [9/30] - Train Loss: 424.6496 - Train Acc: 92.48% - Test Acc: 88.00%\n",
      "Epoch [10/30] - Train Loss: 404.9464 - Train Acc: 92.24% - Test Acc: 87.80%\n",
      "Epoch [11/30] - Train Loss: 418.4439 - Train Acc: 92.84% - Test Acc: 88.00%\n",
      "Epoch [12/30] - Train Loss: 414.8336 - Train Acc: 93.23% - Test Acc: 88.17%\n",
      "Epoch [13/30] - Train Loss: 413.0227 - Train Acc: 92.76% - Test Acc: 87.65%\n",
      "Epoch [14/30] - Train Loss: 442.8594 - Train Acc: 93.29% - Test Acc: 88.48%\n",
      "Epoch [15/30] - Train Loss: 411.7193 - Train Acc: 92.94% - Test Acc: 87.79%\n",
      "Epoch [16/30] - Train Loss: 401.2784 - Train Acc: 92.66% - Test Acc: 87.45%\n",
      "Epoch [17/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [18/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [19/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [20/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [21/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [22/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [23/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [24/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [25/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [26/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [27/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [28/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [29/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [30/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Final loss: nan\n",
      "Final train accuracy: 10.0\n",
      "Final valid accuracy: 10.0\n",
      "Using Learning rate: 1 and Activation: relu\n",
      "Epoch [1/30] - Train Loss: 4333.7049 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [2/30] - Train Loss: 4331.3491 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [3/30] - Train Loss: 4332.0206 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [4/30] - Train Loss: 4330.6675 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [5/30] - Train Loss: 4331.9121 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [6/30] - Train Loss: 4331.4807 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [7/30] - Train Loss: 4331.6880 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [8/30] - Train Loss: 4331.1469 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [9/30] - Train Loss: 4330.8661 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [10/30] - Train Loss: 4330.8712 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [11/30] - Train Loss: 4331.7112 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [12/30] - Train Loss: 4330.7041 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [13/30] - Train Loss: 4330.7740 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [14/30] - Train Loss: 4331.7766 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [15/30] - Train Loss: 4330.7797 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [16/30] - Train Loss: 4331.0505 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [17/30] - Train Loss: 4330.8932 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [18/30] - Train Loss: 4331.4251 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [19/30] - Train Loss: 4330.8325 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [20/30] - Train Loss: 4331.4165 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [21/30] - Train Loss: 4330.4648 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [22/30] - Train Loss: 4331.0036 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [23/30] - Train Loss: 4332.3566 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [24/30] - Train Loss: 4330.6961 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [25/30] - Train Loss: 4331.4334 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [26/30] - Train Loss: 4331.8615 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [27/30] - Train Loss: 4331.4984 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [28/30] - Train Loss: 4331.2725 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [29/30] - Train Loss: 4332.1488 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [30/30] - Train Loss: 4331.8964 - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Final loss: 4331.896364927292\n",
      "Final train accuracy: 10.0\n",
      "Final valid accuracy: 10.0\n",
      "Using Learning rate: 10 and Activation: relu\n",
      "Epoch [1/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [2/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [3/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [4/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [5/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [6/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [7/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [8/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [9/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [10/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [11/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [12/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [13/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [14/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [15/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [16/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [17/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [18/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [19/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [20/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [21/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [22/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [23/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [24/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [25/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [26/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [27/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [28/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [29/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Epoch [30/30] - Train Loss: nan - Train Acc: 10.00% - Test Acc: 10.00%\n",
      "Final loss: nan\n",
      "Final train accuracy: 10.0\n",
      "Final valid accuracy: 10.0\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Question 3.4\n",
    "experimenting_with_learning_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "92c71298-ddb3-4829-ae4b-759d5fe01204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Experimenting with dropout\n",
      "Using dropout rate: 0.3\n",
      "Epoch [1/30] - Train Loss: 1062.9818 - Train Acc: 84.95% - Test Acc: 84.14%\n",
      "Epoch [2/30] - Train Loss: 649.4358 - Train Acc: 89.45% - Test Acc: 87.96%\n",
      "Epoch [3/30] - Train Loss: 560.0340 - Train Acc: 89.14% - Test Acc: 87.39%\n",
      "Epoch [4/30] - Train Loss: 501.0179 - Train Acc: 90.74% - Test Acc: 88.72%\n",
      "Epoch [5/30] - Train Loss: 455.7441 - Train Acc: 92.33% - Test Acc: 90.26%\n",
      "Epoch [6/30] - Train Loss: 414.8983 - Train Acc: 92.97% - Test Acc: 90.14%\n",
      "Epoch [7/30] - Train Loss: 383.0813 - Train Acc: 92.96% - Test Acc: 89.98%\n",
      "Epoch [8/30] - Train Loss: 354.0021 - Train Acc: 93.70% - Test Acc: 90.25%\n",
      "Epoch [9/30] - Train Loss: 319.4971 - Train Acc: 94.65% - Test Acc: 90.97%\n",
      "Epoch [10/30] - Train Loss: 302.9978 - Train Acc: 95.27% - Test Acc: 90.62%\n",
      "Epoch [11/30] - Train Loss: 269.1865 - Train Acc: 95.31% - Test Acc: 90.86%\n",
      "Epoch [12/30] - Train Loss: 255.3331 - Train Acc: 95.80% - Test Acc: 90.64%\n",
      "Epoch [13/30] - Train Loss: 231.1877 - Train Acc: 96.44% - Test Acc: 91.05%\n",
      "Epoch [14/30] - Train Loss: 212.0558 - Train Acc: 96.40% - Test Acc: 91.01%\n",
      "Epoch [15/30] - Train Loss: 199.6969 - Train Acc: 96.65% - Test Acc: 90.84%\n",
      "Epoch [16/30] - Train Loss: 181.4706 - Train Acc: 97.17% - Test Acc: 90.96%\n",
      "Epoch [17/30] - Train Loss: 168.0607 - Train Acc: 97.49% - Test Acc: 90.83%\n",
      "Epoch [18/30] - Train Loss: 157.6732 - Train Acc: 97.87% - Test Acc: 90.89%\n",
      "Epoch [19/30] - Train Loss: 144.5372 - Train Acc: 97.94% - Test Acc: 91.14%\n",
      "Epoch [20/30] - Train Loss: 136.9192 - Train Acc: 97.83% - Test Acc: 90.27%\n",
      "Epoch [21/30] - Train Loss: 124.4209 - Train Acc: 98.35% - Test Acc: 91.04%\n",
      "Epoch [22/30] - Train Loss: 124.2873 - Train Acc: 97.87% - Test Acc: 90.40%\n",
      "Epoch [23/30] - Train Loss: 113.4198 - Train Acc: 98.10% - Test Acc: 90.77%\n",
      "Epoch [24/30] - Train Loss: 105.3186 - Train Acc: 98.91% - Test Acc: 90.82%\n",
      "Epoch [25/30] - Train Loss: 100.5563 - Train Acc: 97.91% - Test Acc: 90.48%\n",
      "Epoch [26/30] - Train Loss: 98.9279 - Train Acc: 98.96% - Test Acc: 91.03%\n",
      "Epoch [27/30] - Train Loss: 92.7519 - Train Acc: 98.73% - Test Acc: 90.78%\n",
      "Epoch [28/30] - Train Loss: 89.8978 - Train Acc: 98.76% - Test Acc: 90.66%\n",
      "Epoch [29/30] - Train Loss: 84.6907 - Train Acc: 98.65% - Test Acc: 90.60%\n",
      "Epoch [30/30] - Train Loss: 74.7682 - Train Acc: 98.59% - Test Acc: 90.22%\n",
      "Final loss: 74.76817650191879\n",
      "Final train accuracy: 98.58833333333334\n",
      "Final valid accuracy: 90.22\n"
     ]
    }
   ],
   "source": [
    "#Question 3.5\n",
    "experimenting_dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3859b-cdf3-4cdf-85ee-cdcb3adf2a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
